{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that splits data into train, validation, and test sets\n",
    "def train_val_test_split(X, Y, train_split=0.8, val_split=0.1, test_split=0.1, random_seed=seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_split, random_state=random_seed)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_split/(train_split+val_split), random_state=random_seed)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "# evaluation function\n",
    "def evaluation(y_pred, y_test):\n",
    "    valence_predicted = np.array(y_pred)[:, 0]\n",
    "    arousal_predicted = np.array(y_pred)[:, 1]\n",
    "    valence_test = np.array(y_test)[:, 0]\n",
    "    arousal_test = np.array(y_test)[:, 1]\n",
    "    # MSE\n",
    "    valence_mse = mean_squared_error(valence_test, valence_predicted)\n",
    "    arousal_mse = mean_squared_error(arousal_test, arousal_predicted)\n",
    "    # RMSE\n",
    "    valence_rmse = np.sqrt(valence_mse)\n",
    "    arousal_rmse = np.sqrt(arousal_mse)\n",
    "    # MAE\n",
    "    valence_mae = mean_absolute_error(valence_test, valence_predicted)\n",
    "    arousal_mae = mean_absolute_error(arousal_test, arousal_predicted)\n",
    "    # R^2 Score\n",
    "    valence_r2 = r2_score(valence_test, valence_predicted)\n",
    "    arousal_r2 = r2_score(arousal_test, arousal_predicted)\n",
    "\n",
    "    print(\"Valence MSE:\", valence_mse)\n",
    "    print(\"Arousal MSE:\", arousal_mse)\n",
    "    print(\"Valence RMSE:\", valence_rmse)\n",
    "    print(\"Arousal RMSE:\", arousal_rmse)\n",
    "    print(\"Valence MAE:\", valence_mae)\n",
    "    print(\"Arousal MAE:\", arousal_mae)\n",
    "    print(\"Valence R^2 Score:\", valence_r2)\n",
    "    print(\"Arousal R^2 Score:\", arousal_r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"../data/processed_multi_modal.csv\")\n",
    "\n",
    "audio_features_top4 = [\"loudness\", \"instrumentalness\", \"time_signature\", \"energy\"]\n",
    "audio_features_top9 = [\"loudness\", \"instrumentalness\", \"time_signature\", \"energy\", \"danceability\", \"tempo\", \"acousticness\", \"key\", \"speechiness\"]\n",
    "audio_features_all  = [\"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"tempo\", \"time_signature\"]\n",
    "\n",
    "lyric_features = [\"compound\",\"neg\", \"pos\", \"neu\", \"pca_tfidf0\", \"pca_tfidf1\", \"pca_tfidf2\", \"pca_tfidf3\", \"pca_tfidf4\", \"pca_tfidf5\", \"pca_tfidf6\", \"pca_tfidf7\", \n",
    "                  \"pca_tfidf8\", \"pca_tfidf9\", \"pca_tfidf10\", \"pca_tfidf11\", \"pca_tfidf12\", \"pca_tfidf13\", \"pca_tfidf14\", \"pca_tfidf15\", \"pca_tfidf16\", \"pca_tfidf17\", \n",
    "                  \"pca_tfidf18\", \"pca_tfidf19\", \"pca_tfidf20\", \"pca_tfidf21\", \"pca_tfidf22\", \"pca_tfidf23\", \"pca_tfidf24\", \"pca_tfidf25\", \"pca_tfidf26\", \"pca_tfidf27\", \n",
    "                  \"pca_tfidf28\", \"pca_tfidf29\", \"pca_tfidf30\", \"pca_tfidf31\", \"pca_tfidf32\", \"pca_tfidf33\", \"pca_tfidf34\", \"pca_tfidf35\", \"pca_tfidf36\", \"pca_tfidf37\", \n",
    "                  \"pca_tfidf38\", \"pca_tfidf39\", \"pca_tfidf40\", \"pca_tfidf41\", \"pca_tfidf42\", \"pca_tfidf43\", \"pca_tfidf44\", \"pca_tfidf45\", \"pca_tfidf46\", \"pca_tfidf47\", \n",
    "                  \"pca_tfidf48\", \"pca_tfidf49\"]\n",
    "\n",
    "ys_features = [\"valence\", \"arousal\"]\n",
    "\n",
    "df_audio = df_data[audio_features_top9]\n",
    "df_lyric = df_data[lyric_features]\n",
    "df_multi = df_data[audio_features_top9 + lyric_features]\n",
    "df_ys    = df_data[ys_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = df_multi, df_ys\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_regressor = SVR() # base regressor\n",
    "svr_model = MultiOutputRegressor(base_regressor)\n",
    "\n",
    "# parameters to be tuned\n",
    "param_grid = {\n",
    "    \"estimator__kernel\": [\"linear\", \"rbf\", \"poly\"],  # kernel types\n",
    "    \"estimator__C\": [1, 5, 10]                       # regularization parameter\n",
    "}\n",
    "\n",
    "# grid search on both outputs simultaneously\n",
    "grid_search = GridSearchCV(svr_model, param_grid, scoring=\"r2\", verbose=1, n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(X_val, y_val)  # X_val: Validation input features, y_val: Validation target variables\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C, best_kernal = best_params[\"estimator__C\"], best_params[\"estimator__kernel\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with the best parameters\n",
    "svr_model_best = MultiOutputRegressor(SVR(C=best_C, kernel=best_kernal))\n",
    "\n",
    "# Train the model on the training data\n",
    "svr_model_best.fit(X_train, y_train) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr_model_best.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
